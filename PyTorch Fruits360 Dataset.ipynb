{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is a powerful deep learning framework for Python that specializes in the creation of image classification systems. This notebook will serve as a practical example of how to implement a custom image classificiation network in Pytorch, using the Fruits 360 dataset.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off with, we'll begin by importing all the libraries we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then set the directory for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set main directory for use in getting training/testing data\n",
    "\n",
    "main_dir = \"./fruits-360/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up the transforms we are going to use for the datasets.  We'll do this for both the training and testing datasets, and then use the DataLoader to create iterable objects out of the preprocessed data. We'lll do some random rotating and flipping of the images, and we'll also normalize the data. It's critical to transform the data into a Tensor so that the deep neural network model can interpret it. Applying random perturbations to the training dataset can help make the image classifier more robust, able to recognize images that have been altered in certain ways from your target images.\n",
    "\n",
    "Traditionally, you don't pass the image perturbations to the test dataset, although you can. \n",
    "\n",
    "After we declare the transforms, we'll join the train and test directories to the base URL to get the full paths and then make our data iterable with the DataLoader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare transforms for train and test data\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(25),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),\n",
    "                         (0.5,0.5,0.5)),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),\n",
    "                         (0.5,0.5,0.5)),])\n",
    "\n",
    "# Set the directories for the training and testing data, create the datasets with the transforms\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(main_dir, 'Train/'), transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(os.path.join(main_dir, 'Test/'), transform=test_transforms)\n",
    "\n",
    "# Use the dataloaders to create iterable objects out of the datasets\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to set the number of classes in the dataset, as the final output of the model needs to be equal to the number of classes. We set the training device here too, cuda - if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of classes\n",
    "classes = 118\n",
    "\n",
    "# Specify the device to use\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now go about creating the deep neural network. We have our custom model inherit from `nn.Module`, and we define both the convolutional portion of the network as well as the fully connected layers/classifier portion of the model. We then add these together in a method and flatten the inputs heading into the fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Model to use for training\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(8*8*16, 300)\n",
    "        self.fc2 = nn.Linear(300, classes)\n",
    "        self.conv1_bn = nn.BatchNorm2d(8)\n",
    "        self.conv2_bn = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    # Can combine layers and activations if you want:\n",
    "    # Ex. X = self.conv1_bn(self.conv1(X))\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.conv1(X)\n",
    "        X = self.conv1_bn(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.pool(X)\n",
    "        X = self.conv2(X)\n",
    "        X = self.conv2_bn(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.pool(X)\n",
    "        X = X.view(-1, 8*8*16)\n",
    "        X = self.fc1(X)\n",
    "        X = F.relu(X)\n",
    "        X = F.dropout(X)\n",
    "        X = self.fc2(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now instantiate the model in a variable and declare our optimizer, criterion, and learning rate. We'll also specify the device to use, GPU/cuda if available. If you wanted, you could also use a learning rate schedule here to decrement the learning rate when it reaches a pleateau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of training epochs and learning rate\n",
    "# May also want to use learning rate scheduler\n",
    "\n",
    "epochs = 40\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Declare the model, loss criterion, and chosen optimizer\n",
    "\n",
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the function to train the model. We'll set the model to training mode and decrement the learning rate at the start of every epoch. We also need to get the current batch, the image data, and the target from the train loader. We'll set the data and targets as variables, and send them to the device. We then need to zero the gradients before we start training. We run the data through the model and save the output in a variable. We then calculate the loss and carry out backpropogation, and after backprop we can carry out a step of optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll just evaluate the model. We set the model to eval mode, and create variables to hold the loss and number of instances correctly classified. We then get the image data and targets from the DataLoader for the test data, and like before, run the data through the model. We can do this just by saying \"else\", since if it isn't in training mode logically it must be in evaluation mode.\n",
    "\n",
    "Finally, we can print out some metrics and analyze the results of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "End Epoch\n",
      "Training Accuracy: 20.59%\n",
      "Testing Accuracy: 34.41%\n",
      "---------\n",
      "End Epoch\n",
      "Training Accuracy: 53.65%\n",
      "Testing Accuracy: 52.00%\n",
      "---------\n",
      "End Epoch\n",
      "Training Accuracy: 70.98%\n",
      "Testing Accuracy: 61.81%\n",
      "---------\n",
      "End Epoch\n",
      "Training Accuracy: 79.19%\n",
      "Testing Accuracy: 66.87%\n",
      "---------\n",
      "End Epoch\n",
      "Training Accuracy: 84.81%\n",
      "Testing Accuracy: 71.50%\n",
      "---------\n",
      "End Epoch\n",
      "Training Accuracy: 88.11%\n",
      "Testing Accuracy: 73.51%\n",
      "---------\n",
      "End Epoch\n",
      "Training Accuracy: 90.33%\n",
      "Testing Accuracy: 75.31%\n",
      "---------\n",
      "End Epoch\n",
      "Training Accuracy: 92.10%\n",
      "Testing Accuracy: 78.92%\n"
     ]
    }
   ],
   "source": [
    "# Declare variables to hold the training and testing loss\n",
    "# Which will be updated over the course of the epoch\n",
    "\n",
    "epoch_loss_train = []\n",
    "epoch_loss_test = []\n",
    "\n",
    "\n",
    "# For our chosen number of epochs, train and check performance on test set\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    # Declare variables to hold metrics\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    # For the features and labels in the train loader\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        # Declare the inputs and labels, zero the gradients,\n",
    "        # run the inputs through the model and calculate the loss\n",
    "        inputs, labels = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Get the most likely prediction\n",
    "        # Do backprop to calculate gradient and optimize\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the values\n",
    "        train_loss += loss.item()\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (prediction == labels).sum().item()\n",
    "\n",
    "    else:\n",
    "\n",
    "        test_loss = 0.0\n",
    "        test_total = 0\n",
    "        test_correct = 0\n",
    "\n",
    "        # Set to no_grad for purposes of evaluation\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_images, test_targets in test_loader:\n",
    "                images, targets = test_images.to(device), test_targets.to(device)\n",
    "                test_outputs = model(images)\n",
    "                difference = criterion(test_outputs, targets)\n",
    "                test_loss += difference.item()\n",
    "                _, test_pred = torch.max(test_outputs.data, 1)\n",
    "                test_total += targets.size(0)\n",
    "                test_correct += (test_pred == targets).sum().item()\n",
    "\n",
    "        epoch_loss_train.append(train_loss/len(train_loader))\n",
    "        epoch_loss_test.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"---------\")\n",
    "        print(\"End Epoch\")\n",
    "        print('Training Accuracy: {:.2f}%'.format(100 * train_correct / train_total))\n",
    "        print('Testing Accuracy: {:.2f}%'.format(100 * test_correct / test_total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
